{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"995efe57"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","\n","import PIL\n","from tqdm import tqdm\n","from PIL import Image\n","from keras.preprocessing.image import ImageDataGenerator\n","from matplotlib import rcParams\n","\n","from keras.models import Sequential\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow import keras\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.imagenet_utils import preprocess_input\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n","from tensorflow.keras.utils import to_categorical\n"],"id":"995efe57"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYtGQ4MPnPPc"},"outputs":[],"source":["#If running on Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"jYtGQ4MPnPPc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"94520e5f"},"outputs":[],"source":["#Change as required\n","root = '/content/drive/MyDrive/ML_Project'\n","train_csv = root + '/train.csv'\n","train_images = root + '/train_images'\n","test_images = root + '/test_images'"],"id":"94520e5f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7902147"},"outputs":[],"source":["#Read in training data from .csv and address the specie labelling errors\n","train_df = pd.read_csv(train_csv)\n","train_df['image_path'] = train_images +'/'+ train_df['image']\n","\n","train_df.loc[train_df.species.str.contains('beluga'), 'species'] = 'beluga_whale'\n","train_df.loc[train_df.species.str.contains('globis'), 'species'] = 'globis_whale'\n","\n","train_df.loc[train_df.species.str.contains('dolpin'), 'species'] = 'bottlenose_dolphin'\n","train_df.loc[train_df.species.str.contains('kiler'), 'species'] = 'killer_whale'\n","\n","print(f'List of Unique Species:\\n {train_df.species.unique()}')\n","\n","print(f'\\n Number of individual species, updated: {train_df.species.nunique()} \\n')\n"],"id":"a7902147"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zn8hLiPaM3LL"},"outputs":[],"source":["def imageLoad(paths):\n","\n","  X_train = np.zeros((len(paths), 56, 80, 3))\n","  for i in tqdm(range(len(paths))):\n","\n","    #Open image from path\n","    img = image.load_img(paths[i], target_size = (56, 80), color_mode = 'rgb')\n","    #Convert to array\n","    x = image.img_to_array(img)\n","    #Expand dimensions\n","    x = np.expand_dims(x, axis = 0)\n","    #Preprocess input for keras model\n","    x = preprocess_input(x)\n","    X_train[i] = x\n","  return X_train\n"],"id":"Zn8hLiPaM3LL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hl34DR1JKzMV"},"outputs":[],"source":["#Read in all augmented images.\n","augImg_df = pd.read_csv(root + '/final_generated_train_images.csv')\n","augImg_df = augImg_df[['individual_id','species', 'image_path']]\n","print(f'Number of individual IDs: {augImg_df.individual_id.nunique()}')\n"],"id":"Hl34DR1JKzMV"},{"cell_type":"code","source":["train_df = train_df.sort_values(by=['individual_id']).reset_index(drop = True)\n","\n","#Get three images for each individual ID\n","train_df = train_df.groupby(by=['individual_id']).head(3).reset_index(drop = True)\n"],"metadata":{"id":"0xU_M0wDWkeW"},"id":"0xU_M0wDWkeW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jx_zzw2-zaQJ"},"outputs":[],"source":["#Add the augmented images\n","train_total_df = train_df.append(augImg_df).reset_index(drop = True)\n","\n","#Redundancy to make sure there are only 3 images per ID\n","train_total_df = train_total_df.groupby(by=['individual_id']).head(3).reset_index(drop = True)"],"id":"jx_zzw2-zaQJ"},{"cell_type":"code","source":["ID= pd.DataFrame(train_total_df.individual_id.value_counts())\n","\n","ID_df = pd.DataFrame(columns = ['individual_id', 'image_freq'])\n","\n","ID_df['individual_id'] = ID.index\n","ID_df['image_freq'] = ID.values.astype(int)\n","\n","print(ID_df)"],"metadata":{"id":"f1yj7-jTZuLp"},"id":"f1yj7-jTZuLp","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAHQN2JEnMXc"},"outputs":[],"source":["#Sanity check. Should have 15587 classes\n","print(train_total_df['individual_id'].nunique())"],"id":"mAHQN2JEnMXc"},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', None)\n","#Split the training set into a validation set of 1 image per ID\n","valid_set = train_total_df.groupby('individual_id').head(1).sort_values(by = ['individual_id']).reset_index(drop = True)\n","print(valid_set)\n","train_df2 = train_total_df[~train_total_df.index.isin(valid_set.index)].sort_values(by = ['individual_id']).reset_index(drop = True)\n","print(train_df2)\n"],"metadata":{"id":"D--nTwKp1VC4"},"id":"D--nTwKp1VC4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xWuUgVJUqiI"},"outputs":[],"source":["#Load the training set\n","Xtrain = imageLoad(train_df2['image_path'])"],"id":"0xWuUgVJUqiI"},{"cell_type":"code","source":["#Load the validation set\n","Valid_X = imageLoad(valid_set['image_path'])"],"metadata":{"id":"3V7dvAd71h4N"},"id":"3V7dvAd71h4N","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_3wBKf-1o_r"},"outputs":[],"source":["#Rescale the array values to be betweeon 0-1\n","Xtrain /= 255\n","Valid_X /=255"],"id":"r_3wBKf-1o_r"},{"cell_type":"code","source":["#Function for OHE labels\n","def labels(y):\n","    values = np.array(y)\n","    label_encoder = LabelEncoder()\n","    label_encoder = label_encoder.fit(values)\n","    lEncoded = label_encoder.transform(values)\n","    onehot_encoder = OneHotEncoder(sparse=False)\n","    lEncoded = lEncoded.reshape(len(lEncoded), 1)\n","    onehot_encoder = onehot_encoder.fit(lEncoded)\n","    OHEncoded = onehot_encoder.transform(lEncoded)\n","    y = OHEncoded\n","    return y"],"metadata":{"id":"Id1Y2JA6Ufm3"},"id":"Id1Y2JA6Ufm3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#OHE target data for both training and validation\n","\n","ytrain = train_df2['individual_id']\n","Ytrain = labels(ytrain)\n","\n","valid_y = valid_set['individual_id']\n","Valid_Y = labels(valid_y)"],"metadata":{"id":"Nt8huENETV9V"},"id":"Nt8huENETV9V","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS_nABTy2DHN"},"outputs":[],"source":["#MODEL V2\n","model = Sequential()\n","\n","# First convolution extracts 16 filters that are 3x3\n","# Convolution is followed by batch normalization and a max-pooling layer with a 2x2 window\n","model.add(Conv2D(16, 3, activation = 'relu', input_shape = (56, 80, 3)))\n","model.add(BatchNormalization(axis = 3))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","# Second convolution extracts 32 filters that are 3x3\n","# Convolution is followed by batch normalization and a max-pooling layer with a 2x2 window\n","model.add(Conv2D(32, 3, activation='relu'))\n","model.add(BatchNormalization(axis = 3))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","# Third convolution extracts 64 filters that are 3x3\n","# Convolution is followed by an average-pooling layer with a 2x2 window and a dropout layer set to 0.4\n","model.add(Conv2D(64, 3, activation='relu'))\n","model.add(AveragePooling2D(pool_size = (2,2)))\n","model.add(Dropout(0.4))\n","\n","# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n","model.add(Flatten())\n","\n","# Create a fully connected layer with ReLU activation and 256 hidden units and a dropout layer set to 0.4\n","model.add(Dense(256, activation=\"relu\"))\n","model.add(Dropout(0.4))\n","\n","# Create output layer with 15587 nodes and softmax activation\n","model.add(Dense(train_df['individual_id'].nunique(), activation='softmax'))\n","\n","# Compile model:\n","model.summary()\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])"],"id":"CS_nABTy2DHN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBobystd3bTu"},"outputs":[],"source":["#Save the model after epoch\n","callbacks = [ModelCheckpoint(root+\"/model_checkpoint\", monitor='acc', )]"],"id":"wBobystd3bTu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtbU3GTA3eGs"},"outputs":[],"source":["#Fit the model. Parameters are not tuned and are initial values\n","history = model.fit(\n","       x = Xtrain,\n","       y = Ytrain,\n","       epochs = 40,\n","       batch_size = 128,\n","       verbose = 1,\n","       callbacks = callbacks,\n","       validation_data = (Valid_X, Valid_Y)\n","       )"],"id":"LtbU3GTA3eGs"},{"cell_type":"code","source":["#plot model accuracy\n","plt.figure(dpi=1200)\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'val'], loc='upper left')\n","#plt.savefig('Accuracy_plot_1.png',bbox_inches='tight')"],"metadata":{"id":"BHFoNSmClKp0"},"id":"BHFoNSmClKp0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot model loss\n","plt.figure(dpi=1200)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'val'], loc='upper left')\n","#plt.savefig('Loss_plot_1.png',bbox_inches='tight')"],"metadata":{"id":"Doq3Ew1jmaxs"},"id":"Doq3Ew1jmaxs","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JUfNlx5e4EC7"},"outputs":[],"source":["model.save(root + '/models/Model_CNN_Validation')"],"id":"JUfNlx5e4EC7"}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}