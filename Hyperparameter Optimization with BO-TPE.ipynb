{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"995efe57"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","import cv2\n","import imagesize\n","import PIL\n","from tqdm import tqdm\n","from PIL import Image\n","from keras.preprocessing.image import ImageDataGenerator\n","from matplotlib import rcParams\n","\n","from keras.models import Sequential\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow import keras\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.imagenet_utils import preprocess_input\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n","from tensorflow.keras.utils import to_categorical\n"],"id":"995efe57"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYtGQ4MPnPPc"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"jYtGQ4MPnPPc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"94520e5f"},"outputs":[],"source":["root = '/content/drive/MyDrive/ML_Project'\n","train_csv = root + '/train.csv'\n","train_images = root + '/train_images'\n","test_images = root + '/test_images'"],"id":"94520e5f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7902147"},"outputs":[],"source":["#Read in training data from .csv and address the specie labelling errors\n","train_df = pd.read_csv(train_csv)\n","train_df['image_path'] = train_images +'/'+ train_df['image']\n","\n","train_df.loc[train_df.species.str.contains('beluga'), 'species'] = 'beluga_whale'\n","train_df.loc[train_df.species.str.contains('globis'), 'species'] = 'globis_whale'\n","\n","train_df.loc[train_df.species.str.contains('dolpin'), 'species'] = 'bottlenose_dolphin'\n","train_df.loc[train_df.species.str.contains('kiler'), 'species'] = 'killer_whale'\n","\n","print(f'List of Unique Species:\\n {train_df.species.unique()}')\n","\n","print(f'\\n Number of individual species, updated: {train_df.species.nunique()} \\n')"],"id":"a7902147"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zn8hLiPaM3LL"},"outputs":[],"source":["def imageLoad(paths):\n","  \n","  X_train = np.zeros((len(paths), 56, 80, 3))\n","  for i in tqdm(range(len(paths))):\n","\n","    #Open image from path\n","    img = image.load_img(paths[i], target_size = (56, 80), color_mode = 'rgb')\n","    #Convert to array\n","    x = image.img_to_array(img)\n","    #Expand dimensions\n","    x = np.expand_dims(x, axis = 0)\n","    #Preprocess input for keras model\n","    x = preprocess_input(x)\n","    X_train[i] = x\n","  return X_train\n"],"id":"Zn8hLiPaM3LL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hl34DR1JKzMV"},"outputs":[],"source":["#Read in all augmented images. \n","augImg_df = pd.read_csv(root + '/final_generated_train_images.csv')\n","augImg_df = augImg_df[['individual_id','species', 'image_path']]\n","print(f'Number of individual IDs: {augImg_df.individual_id.nunique()}')\n"],"id":"Hl34DR1JKzMV"},{"cell_type":"code","source":["train_df = train_df.sort_values(by=['individual_id']).reset_index(drop = True)\n","\n","#Get three images for each individual ID\n","train_df = train_df.groupby(by=['individual_id']).head(3).reset_index(drop = True)\n"],"metadata":{"id":"0xU_M0wDWkeW"},"id":"0xU_M0wDWkeW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jx_zzw2-zaQJ"},"outputs":[],"source":["#Add the augmented images\n","train_total_df = train_df.append(augImg_df).reset_index(drop = True)\n","\n","#Redundancy to make sure there are only 3 images per ID\n","train_total_df = train_total_df.groupby(by=['individual_id']).head(3).reset_index(drop = True)"],"id":"jx_zzw2-zaQJ"},{"cell_type":"code","source":["ID= pd.DataFrame(train_total_df.individual_id.value_counts())\n","\n","ID_df = pd.DataFrame(columns = ['individual_id', 'image_freq'])\n","\n","ID_df['individual_id'] = ID.index\n","ID_df['image_freq'] = ID.values.astype(int)\n","\n","print(ID_df)"],"metadata":{"id":"f1yj7-jTZuLp"},"id":"f1yj7-jTZuLp","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAHQN2JEnMXc"},"outputs":[],"source":["#Sanity check. Should have 15587 classes\n","print(train_total_df['individual_id'].nunique())"],"id":"mAHQN2JEnMXc"},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', None)\n","#Split the training set into a validation set of 1 image per ID\n","valid_set = train_total_df.groupby('individual_id').head(1).sort_values(by = ['individual_id']).reset_index(drop = True)\n","print(valid_set)\n","train_df2 = train_total_df[~train_total_df.index.isin(valid_set.index)].sort_values(by = ['individual_id']).reset_index(drop = True)\n","print(train_df2)\n"],"metadata":{"id":"D--nTwKp1VC4"},"id":"D--nTwKp1VC4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xWuUgVJUqiI"},"outputs":[],"source":["#Load the training set\n","Xtrain = imageLoad(train_df2['image_path'])"],"id":"0xWuUgVJUqiI"},{"cell_type":"code","source":["#Load the validation set\n","Valid_X = imageLoad(valid_set['image_path'])"],"metadata":{"id":"3V7dvAd71h4N"},"id":"3V7dvAd71h4N","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_3wBKf-1o_r"},"outputs":[],"source":["#Rescale the array values to be betweeon 0-1\n","Xtrain /= 255\n","Valid_X /=255"],"id":"r_3wBKf-1o_r"},{"cell_type":"code","source":["#Function for OHE labels\n","def labels(y):\n","    values = np.array(y)\n","    label_encoder = LabelEncoder()\n","    label_encoder = label_encoder.fit(values)\n","    lEncoded = label_encoder.transform(values)\n","    onehot_encoder = OneHotEncoder(sparse=False)\n","    lEncoded = lEncoded.reshape(len(lEncoded), 1)\n","    onehot_encoder = onehot_encoder.fit(lEncoded)\n","    OHEncoded = onehot_encoder.transform(lEncoded)\n","    y = OHEncoded\n","    return y"],"metadata":{"id":"Id1Y2JA6Ufm3"},"id":"Id1Y2JA6Ufm3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#OHE target data for both training and validation\n","\n","ytrain = train_df2['individual_id']\n","Ytrain = labels(ytrain)\n","\n","valid_y = valid_set['individual_id']\n","Valid_Y = labels(valid_y)"],"metadata":{"id":"Nt8huENETV9V"},"id":"Nt8huENETV9V","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS_nABTy2DHN"},"outputs":[],"source":["#from keras import backend as K \n","def CNNmodel(learning_rate, epochs, batch_size, dropout):\n","#MODEL V2\n","  mod = Sequential()\n","\n","  # First convolution extracts 16 filters that are 3x3\n","  # Convolution is followed by max-pooling layer with a 2x2 window\n","  mod.add(Conv2D(16, 3, activation = 'relu', input_shape = (56, 80, 3)))\n","  mod.add(BatchNormalization(axis = 3))\n","  mod.add(MaxPooling2D(pool_size = (2,2)))\n","\n","  # Second convolution extracts 32 filters that are 3x3\n","  # Convolution is followed by max-pooling layer with a 2x2 window\n","  mod.add(Conv2D(32, 3, activation='relu'))\n","  mod.add(BatchNormalization(axis = 3))\n","  mod.add(MaxPooling2D(pool_size = (2,2)))\n","\n","  # Third convolution extracts 64 filters that are 3x3\n","  # Convolution is followed by max-pooling layer with a 2x2 window\n","  mod.add(Conv2D(64, 3, activation='relu'))\n","  mod.add(AveragePooling2D(pool_size = (2,2)))\n","  mod.add(Dropout(dropout))\n","\n","  # Flatten feature map to a 1-dim tensor so we can add fully connected layers\n","  mod.add(Flatten())\n","\n","  # Create a fully connected layer with ReLU activation and 256 hidden units\n","  mod.add(Dense(256, activation=\"relu\"))\n","  mod.add(Dropout(dropout))\n","\n","  # Create output layer with 15587 nodes and softmax activation\n","  mod.add(Dense(train_df2['individual_id'].nunique(), activation='softmax'))\n","\n","  # Create model:\n","  opt = tf.keras.optimizers.Adam(learning_rate=learning_rate) \n","\n","  #model.summary()\n","  mod.compile(loss = 'categorical_crossentropy', \n","                optimizer = opt, \n","                metrics = ['acc'])\n","\n","  callbacks = [ModelCheckpoint(root+\"/model_checkpoint\", monitor='acc', )]\n","\n","  history = mod.fit(Xtrain, y = Ytrain,\n","        batch_size = batch_size,\n","        epochs = epochs,\n","        verbose = 1,\n","        callbacks = callbacks,\n","        validation_data = (Valid_X, Valid_Y)\n","        )\n","  return mod"],"id":"CS_nABTy2DHN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtbU3GTA3eGs"},"outputs":[],"source":["#HPO Implementation - BO-TPE\n","import pickle\n","from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n","from sklearn.model_selection import cross_val_score\n","from scikeras.wrappers import KerasClassifier\n","\n","def objective(params):\n","\n","    params = {\n","        'learning_rate': abs(int(params['learning_rate'])),\n","        'batch_size': abs(int(params['batch_size'])),\n","        'epochs': abs(int(params['epochs'])),\n","        'dropout': abs(int(params['dropout']))\n","    }\n","    clf = KerasClassifier(CNNmodel,**params, verbose = 0)\n","\n","    score = -np.mean(cross_val_score(clf, Valid_X, Valid_Y, cv=3, \n","                                    scoring=\"accuracy\")) #ran on the validation data as it is as small as possible (only one image per class)\n","\n","    return {'loss': score, 'status': STATUS_OK }\n","\n","# Define the hyperparameter configuration space\n","space = {\n","    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1)),\n","    'batch_size': hp.choice('batch_size', [32, 64, 128, 256]),\n","    'epochs': hp.quniform('epochs', 20, 60, 10),\n","    'dropout': hp.quniform('dropout', 0.2, 0.5, 0.1),\n","}\n","\n","trials = Trials() #implement trials in order to save the parameter data \n","\n","best = fmin(fn=objective, #function to minimize \n","            space=space, #hyperparameter space \n","            algo=tpe.suggest, #TPE \n","            max_evals=5,\n","            trials=trials\n","            ) #performs 5 trials inital trials\n","\n","pickle.dump(trials,  open('trials.p', 'wb'))  # dump data to file\n","trials = pickle.load(open(\"trials.p\",'rb')) #load it again to trials \n","\n","best = fmin(fn=objective, #function to minimize \n","            space=space, #hyperparameter space \n","            algo=tpe.suggest, #TPE \n","            max_evals=10,\n","            trials=trials\n","            ) #performs another 5 trials to reach 10 trials total \n","\n","print(\"CNN: Hyperopt estimated optimum {}\".format(best))"],"id":"LtbU3GTA3eGs"}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Hyperparameter Optimization with BO-TPE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}